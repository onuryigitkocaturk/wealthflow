{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c2f4d2ce",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PROJECT_ROOT: /Users/omerfsaribal/Uni/5th-Term/FinTech/Project/wealthflow/python-server\n",
      "SRC_DIR: /Users/omerfsaribal/Uni/5th-Term/FinTech/Project/wealthflow/python-server/server/src\n",
      "OUTPUTS_DIR: /Users/omerfsaribal/Uni/5th-Term/FinTech/Project/wealthflow/python-server/server/outputs\n",
      "JSON_DIR: /Users/omerfsaribal/Uni/5th-Term/FinTech/Project/wealthflow/python-server/server/outputs/json\n"
     ]
    }
   ],
   "source": [
    "# imports & paths\n",
    "\n",
    "import json\n",
    "import math\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from sklearn.metrics import mean_absolute_error, mean_squared_error\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "\n",
    "from statsmodels.tsa.arima.model import ARIMA\n",
    "\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import LSTM, Dense\n",
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "\n",
    "from pathlib import Path\n",
    "import sys\n",
    "\n",
    "# --- Proje kökünü ve src klasörünü bul ---\n",
    "CURRENT_DIR = Path.cwd()\n",
    "\n",
    "PROJECT_ROOT = None\n",
    "SRC_DIR = None\n",
    "\n",
    "for base in [CURRENT_DIR, *CURRENT_DIR.parents]:\n",
    "    cand = base / \"server\" / \"src\"\n",
    "    if cand.exists():\n",
    "        PROJECT_ROOT = base\n",
    "        SRC_DIR = cand\n",
    "        break\n",
    "\n",
    "if SRC_DIR is None:\n",
    "    raise RuntimeError(f\"server/src bulunamadı, CURRENT_DIR = {CURRENT_DIR}\")\n",
    "\n",
    "if str(SRC_DIR) not in sys.path:\n",
    "    sys.path.insert(0, str(SRC_DIR))\n",
    "\n",
    "# Çıktı klasörleri\n",
    "OUTPUTS_DIR = PROJECT_ROOT / \"server\" / \"outputs\"\n",
    "JSON_DIR = OUTPUTS_DIR / \"json\"\n",
    "\n",
    "# --- Proje modülleri ---\n",
    "from data_loading import load_clean_data\n",
    "from models_baseline import (\n",
    "    naive_forecast_last_value,\n",
    "    moving_average_forecast,\n",
    "    train_test_split_series,\n",
    ")\n",
    "from portfolio import build_recommended_portfolios\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "15fe1f79",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 3: Load SPY clean data and train/test split\n",
    "\n",
    "# SPY temiz fiyat serisini yükle\n",
    "df_spy = load_clean_data(\"SPY\")\n",
    "\n",
    "# Date index'e al\n",
    "if \"Date\" in df_spy.columns:\n",
    "    df_spy = df_spy.set_index(\"Date\")\n",
    "\n",
    "df_spy = df_spy.sort_index()\n",
    "spy_series = df_spy[\"Close\"].astype(float)\n",
    "\n",
    "print(\"SPY series length:\", len(spy_series))\n",
    "print(\"SPY date range:\", spy_series.index.min(), \"->\", spy_series.index.max())\n",
    "\n",
    "# Time-based split (same idea as models_ml.py / baseline)\n",
    "SPLIT_DATE = \"2023-01-01\"  # istersen 2022-12-31 kullan, önemli olan mantık\n",
    "\n",
    "spy_train, spy_test = train_test_split_series(spy_series, split_date=SPLIT_DATE)\n",
    "\n",
    "print(\"Train length:\", len(spy_train), \"Test length:\", len(spy_test))\n",
    "print(\"Train last date:\", spy_train.index.max(), \"Test first date:\", spy_test.index.min())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3e4408df",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 4: Baseline forecasts (naive & moving average) and metrics\n",
    "\n",
    "horizon = len(spy_test)\n",
    "\n",
    "# Naive: son değeri test boyunca sabit tahmin\n",
    "baseline_naive = naive_forecast_last_value(spy_train, horizon=horizon)\n",
    "\n",
    "# Moving average: son 30 gün ortalamasını sabit tahmin\n",
    "baseline_ma = moving_average_forecast(spy_train, window=30, horizon=horizon)\n",
    "\n",
    "y_true = spy_test.values\n",
    "\n",
    "def compute_metrics(y_true, y_pred, name=\"model\"):\n",
    "    mae = mean_absolute_error(y_true, y_pred)\n",
    "    rmse = math.sqrt(mean_squared_error(y_true, y_pred))\n",
    "    print(f\"{name}: MAE={mae:.4f}, RMSE={rmse:.4f}\")\n",
    "    return mae, rmse\n",
    "\n",
    "mae_naive, rmse_naive = compute_metrics(y_true, baseline_naive, name=\"Naive baseline\")\n",
    "mae_ma, rmse_ma = compute_metrics(y_true, baseline_ma, name=\"MovingAverage baseline\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f4edaae0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 5: ARIMA model on SPY\n",
    "\n",
    "# Basit bir ARIMA(1,1,1) modeli. İstersen order'ı değiştirip oynayabilirsin.\n",
    "arima_order = (1, 1, 1)\n",
    "\n",
    "arima_model = ARIMA(spy_train, order=arima_order)\n",
    "arima_result = arima_model.fit()\n",
    "\n",
    "print(arima_result.summary())\n",
    "\n",
    "# Test horizon kadar ileri tahmin\n",
    "arima_forecast = arima_result.forecast(steps=horizon)\n",
    "\n",
    "mae_arima, rmse_arima = compute_metrics(y_true, arima_forecast, name=f\"ARIMA{arima_order}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7872929f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 6: LSTM helpers (series -> supervised sequences, model builder)\n",
    "\n",
    "def create_lstm_sequences(series: pd.Series, lookback: int = 60):\n",
    "    \"\"\"\n",
    "    series: pandas Series of prices (train kısmı).\n",
    "    lookback: kaç günlük history ile 1 gün sonrası tahmini yapılacak.\n",
    "    \"\"\"\n",
    "    values = series.values.reshape(-1, 1).astype(float)\n",
    "    scaler = MinMaxScaler(feature_range=(0, 1))\n",
    "    scaled = scaler.fit_transform(values)\n",
    "\n",
    "    X, y = [], []\n",
    "    for i in range(lookback, len(scaled)):\n",
    "        X.append(scaled[i - lookback:i, 0])\n",
    "        y.append(scaled[i, 0])\n",
    "\n",
    "    X = np.array(X)\n",
    "    y = np.array(y)\n",
    "\n",
    "    # reshape to (samples, timesteps, features)\n",
    "    X = X.reshape((X.shape[0], X.shape[1], 1))\n",
    "\n",
    "    return X, y, scaler\n",
    "\n",
    "\n",
    "def build_lstm_model(lookback: int = 60):\n",
    "    model = Sequential()\n",
    "    model.add(LSTM(32, input_shape=(lookback, 1)))\n",
    "    model.add(Dense(1))\n",
    "\n",
    "    model.compile(optimizer=\"adam\", loss=\"mse\")\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "53e4e25e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 7: Train LSTM on SPY and multi-step forecast for test period\n",
    "\n",
    "LOOKBACK = 60\n",
    "\n",
    "# Train set üzerinden supervised veri oluştur\n",
    "X_train, y_train_seq, scaler = create_lstm_sequences(spy_train, lookback=LOOKBACK)\n",
    "\n",
    "print(\"X_train shape:\", X_train.shape)\n",
    "print(\"y_train shape:\", y_train_seq.shape)\n",
    "\n",
    "lstm_model = build_lstm_model(lookback=LOOKBACK)\n",
    "\n",
    "early_stop = EarlyStopping(\n",
    "    monitor=\"loss\",\n",
    "    patience=5,\n",
    "    restore_best_weights=True,\n",
    ")\n",
    "\n",
    "history = lstm_model.fit(\n",
    "    X_train,\n",
    "    y_train_seq,\n",
    "    epochs=20,\n",
    "    batch_size=32,\n",
    "    verbose=1,\n",
    "    callbacks=[early_stop],\n",
    ")\n",
    "\n",
    "# Multi-step forecast:\n",
    "#  - Başlangıç penceresi: train'in son LOOKBACK günü\n",
    "#  - Her adımda 1 gün tahmin et, pencereyi kaydır, scaled space'te çalış, sonra inverse transform ile price'a çevir.\n",
    "\n",
    "train_values = spy_train.values.reshape(-1, 1).astype(float)\n",
    "train_scaled = scaler.transform(train_values)\n",
    "history_scaled = list(train_scaled.flatten())\n",
    "\n",
    "lstm_forecast = []\n",
    "\n",
    "for i in range(horizon):\n",
    "    if len(history_scaled) < LOOKBACK:\n",
    "        # yeterli history yoksa boş geç\n",
    "        break\n",
    "\n",
    "    x_input = np.array(history_scaled[-LOOKBACK:])\n",
    "    x_input = x_input.reshape((1, LOOKBACK, 1))\n",
    "\n",
    "    yhat_scaled = lstm_model.predict(x_input, verbose=0)[0, 0]\n",
    "\n",
    "    # history'ye ekle\n",
    "    history_scaled.append(yhat_scaled)\n",
    "\n",
    "    # original price scale'e çevir\n",
    "    yhat_price = scaler.inverse_transform([[yhat_scaled]])[0, 0]\n",
    "    lstm_forecast.append(yhat_price)\n",
    "\n",
    "# LSTM forecast uzunluğu test ile aynı olmalı (aksi halde min len'e göre kırparız)\n",
    "min_len = min(len(y_true), len(lstm_forecast))\n",
    "y_true_lstm = y_true[:min_len]\n",
    "lstm_forecast = np.array(lstm_forecast[:min_len])\n",
    "\n",
    "mae_lstm, rmse_lstm = compute_metrics(y_true_lstm, lstm_forecast, name=\"LSTM\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f7d0cf58",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 8: Comparison table for MAE and RMSE\n",
    "\n",
    "metrics_df = pd.DataFrame(\n",
    "    {\n",
    "        \"MAE\": {\n",
    "            \"Naive\": mae_naive,\n",
    "            \"MovingAverage\": mae_ma,\n",
    "            \"ARIMA\": mae_arima,\n",
    "            \"LSTM\": mae_lstm,\n",
    "        },\n",
    "        \"RMSE\": {\n",
    "            \"Naive\": rmse_naive,\n",
    "            \"MovingAverage\": rmse_ma,\n",
    "            \"ARIMA\": rmse_arima,\n",
    "            \"LSTM\": rmse_lstm,\n",
    "        },\n",
    "    }\n",
    ")\n",
    "\n",
    "metrics_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7cb3df0a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Optional: bar plot for RMSE comparison\n",
    "\n",
    "plt.figure(figsize=(6, 4))\n",
    "metrics_df[\"RMSE\"].plot(kind=\"bar\")\n",
    "plt.title(\"SPY – RMSE comparison (Naive vs MA vs ARIMA vs LSTM)\")\n",
    "plt.ylabel(\"RMSE\")\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d5ce2753",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 9: Real vs predicted prices for SPY (test set)\n",
    "\n",
    "plt.figure(figsize=(12, 6))\n",
    "plt.plot(spy_test.index[:len(y_true_lstm)], y_true_lstm, label=\"Actual (SPY test)\")\n",
    "plt.plot(spy_test.index[:len(baseline_naive)], baseline_naive[:len(y_true_lstm)], label=\"Naive baseline\")\n",
    "plt.plot(spy_test.index[:len(arima_forecast)], arima_forecast[:len(y_true_lstm)], label=\"ARIMA\")\n",
    "plt.plot(spy_test.index[:len(lstm_forecast)], lstm_forecast, label=\"LSTM\")\n",
    "plt.xlabel(\"Date\")\n",
    "plt.ylabel(\"Price\")\n",
    "plt.title(\"SPY – Actual vs Predicted (test period)\")\n",
    "plt.legend()\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "be602873",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 10: Compare baseline forecasts vs ML-enhanced forecasts\n",
    "\n",
    "with (JSON_DIR / \"forecasts_baseline.json\").open(\"r\", encoding=\"utf-8\") as f:\n",
    "    forecasts_baseline = json.load(f)\n",
    "\n",
    "with (JSON_DIR / \"forecasts.json\").open(\"r\", encoding=\"utf-8\") as f:\n",
    "    forecasts_ml = json.load(f)\n",
    "\n",
    "tickers = [\"AAPL\", \"MSFT\", \"SPY\", \"QQQ\", \"TLT\", \"GLD\"]\n",
    "\n",
    "rows = []\n",
    "for t in tickers:\n",
    "    base = forecasts_baseline.get(t, {})\n",
    "    ml = forecasts_ml.get(t, {})\n",
    "\n",
    "    rows.append(\n",
    "        {\n",
    "            \"ticker\": t,\n",
    "            \"base_ret_30d\": base.get(\"expected_return_30d\"),\n",
    "            \"base_vol_30d\": base.get(\"expected_vol_30d\"),\n",
    "            \"ml_ret_30d\": ml.get(\"expected_return_30d\"),\n",
    "            \"ml_vol_30d\": ml.get(\"expected_vol_30d\"),\n",
    "        }\n",
    "    )\n",
    "\n",
    "forecasts_compare_df = pd.DataFrame(rows).set_index(\"ticker\")\n",
    "forecasts_compare_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f6c248dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 11: Build recommended portfolios (if not already built) and inspect JSON\n",
    "\n",
    "# Eğer portfolio.py CLI ile zaten çalıştırdıysan, JSON hazırdır.\n",
    "# Yine de burada bir kez daha build edebiliriz (aynı sonucu üretir).\n",
    "\n",
    "recs = build_recommended_portfolios()\n",
    "\n",
    "# JSON'a yaz (idempotent)\n",
    "portfolio_json_path = JSON_DIR / \"portfolio_recommendations_notebook.json\"\n",
    "with portfolio_json_path.open(\"w\", encoding=\"utf-8\") as f:\n",
    "    json.dump(recs, f, indent=2)\n",
    "\n",
    "portfolio_json_path, recs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "964ffadc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 12: Weights table and bar plot for one profile\n",
    "\n",
    "# recs sözlüğü: profile -> {weights, expected_return, expected_risk}\n",
    "profiles = list(recs.keys())\n",
    "profiles\n",
    "\n",
    "# Weights DataFrame\n",
    "weights_data = {}\n",
    "for profile, data in recs.items():\n",
    "    weights_data[profile] = data[\"weights\"]\n",
    "\n",
    "weights_df = pd.DataFrame(weights_data)\n",
    "weights_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e4562a5d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Bar plot for balanced profile weights\n",
    "\n",
    "profile_name = \"balanced\"\n",
    "w = weights_df[profile_name]\n",
    "\n",
    "plt.figure(figsize=(6, 4))\n",
    "w.plot(kind=\"bar\")\n",
    "plt.title(f\"{profile_name.capitalize()} portfolio weights\")\n",
    "plt.ylabel(\"Weight\")\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1a3857f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Expected return and risk per profile\n",
    "\n",
    "rows = []\n",
    "for profile, data in recs.items():\n",
    "    rows.append(\n",
    "        {\n",
    "            \"profile\": profile,\n",
    "            \"expected_return_30d\": data[\"expected_return\"],\n",
    "            \"expected_risk_30d\": data[\"expected_risk\"],\n",
    "        }\n",
    "    )\n",
    "\n",
    "portfolio_stats_df = pd.DataFrame(rows).set_index(\"profile\")\n",
    "portfolio_stats_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8895335e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Risk-return scatter plot\n",
    "\n",
    "plt.figure(figsize=(6, 4))\n",
    "plt.scatter(\n",
    "    portfolio_stats_df[\"expected_risk_30d\"],\n",
    "    portfolio_stats_df[\"expected_return_30d\"],\n",
    ")\n",
    "\n",
    "for profile in portfolio_stats_df.index:\n",
    "    x = portfolio_stats_df.loc[profile, \"expected_risk_30d\"]\n",
    "    y = portfolio_stats_df.loc[profile, \"expected_return_30d\"]\n",
    "    plt.annotate(profile, (x, y))\n",
    "\n",
    "plt.xlabel(\"Expected 30d Risk\")\n",
    "plt.ylabel(\"Expected 30d Return\")\n",
    "plt.title(\"Portfolio profiles – Risk vs Return (30d)\")\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
